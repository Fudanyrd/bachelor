%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Please Keep each line less than 80 characters.
%
% requires: data/bibtex/slr.bib
% requires packge: natbib,
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{相 关 工 作}

% \par We present a Systematic Literature Review (SLR) including articles
% published in January 2021 and Feburary 2026 that focuses on the use of
% LLM \citep{llmsurvey, csllm} based solutions to Automated Program Repairs 
% (APR).
% The SLR follows the methdology proposed by Kitchenham et al.
% \citep{slrguidese, segress}, used in many SE-related SLRs
% \citep{dl4defence, ml4se, llm4se, llm4se2}. Following the guidelines provided by
% Kitchenham et al., our methodology include three main steps:
% planning the review (i.e. Section~\ref{sec:search}), conducting the review
% (i.e. Section~\ref{sec:selection}), and analyzing the basic review results 
% (i.e. Section~\ref{sec:analysis}).
\par 我们进行了一项系统文献综述（SLR），涵盖了2021年1月至2026年2月期间发表的文章，
重点关注基于大型语言模型（LLM）\citep{llmsurvey, csllm}
的自动程序修复（APR）\citep{asrsurvey, asrbib, aprplm} 解决方案的使用情况。
这项SLR遵循了Kitchenham等人提出的方法论\citep{slrguidese, segress}，该方法已被许
多与软件工程相关的SLR使用\citep{dl4defence, ml4se, llm4se, llm4se2}。
根据Kitchenham等人提供的指南，我们的方法论包括三个主要步骤：
规划审查（即第\ref{sec:search}节），进行审查（即第\ref{sec:selection}节），以及
分析基本审查结果（即第\ref{sec:analysis}节）。

% \section{Search Strategy}\label{sec:search}
\section{检索方法}\label{sec:search}

% \par We employed the \textbf{Precise Search Strategy} \citep{optimalsearch}
% for article search, i.e., we crafted the search string to maximize the relevance 
% of resulting studies. More specifically, we followed the following three steps
% in order to establish a set of relevant studies:
%
% \begin{enumerate}
%  \item Conduct an automated search based on our crafted search string;
%  \item Screen the title and abstract of all articles and filter by
%        inclusion/exclusion criteria;
%  \item Conduct snowballing search on the result of previous step.
% \end {enumerate}

\par 我们采用了\textbf{精确搜索策略} \citep{optimalsearch}进行文章检索，
即我们精心设计了搜索字符串，以最大化结果研究的相关性。更具体地说，
我们遵循以下三个步骤来建立一组相关研究：

\begin{enumerate}
    \item 基于我们设计的搜索字符串进行自动化搜索；
    \item 筛选所有文章的标题和摘要，并根据包含/排除标准进行过滤 (见表\ref{tab:criteria})；
    \item 对上一步的结果进行滚雪球式搜索 (Snowballing Search)。
\end{enumerate}

% \par Our search string needs to combine three set of keywords: 
% one pertaining to software defects, one related to large language models,
% last about the task definition. The complete set of search keywords is
% as follows:
\par 我们的搜索字符串需要结合三组关键词：一组与软件缺陷相关，一组与大型语言模型相关，
最后一组与任务定义相关。完整的搜索关键词如下：
\begin{itemize}
  % \item \textit{Keywords related to LLMs}:
  \item \textit{与大语言模型相关的关键词}:
  large language model, LLM, GPT, CodeX, agent
  % \item \textit{Keywords related to Task Definition}:
  \item \textit{与任务定义相关的关键词}:
  repair, resolve, reproduce, fix, localize
  % \item \textit{Keywords related to software defects}:
  \item \textit{与软件缺陷相关的关键词}:
  bug, defect, vulnerability, crash
\end{itemize}

% \par It is important to note that the list of keywords related to 
% LLMS we setup includes \textit{agent}, that does not seem to be
% necessarily related to LLMs. The reason for this is that we observe 
% recent advancement in agentic technologies \citep{agents}
% and their applications in Software Engineering
% \citep{agent4bugfixempirical,agenticbugreproductioneffective,langgraphbugfix},
%  and that we want to avoid omitting
% articles related to our research as much as possible.
\par 需要注意的是，我们设置的与LLMs相关的关键词列表中包括\textit{agent}，
这似乎并不一定与LLMs相关。
原因是我们观察到最近在代理技术方面的进展\citep{agents}以及它们在软件
工程中的应用
\citep{agent4bugfixempirical,agenticbugreproductioneffective,langgraphbugfix}，
我们希望尽可能避免遗漏与我们的研究相关的文章。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{Search Databases}. After determining the search strings, we
% employed the SLR Tool\citep{slrtool} and conducted
% an automated search across four widely used databases
% \footnote{ACM Digital Library, arXiv, IEEE Xplore, Springer}, 
% which cover most published
% articles and preprints of under-review articles. Given that the first
% LLM trained on code corpus was published in 2021\citep{codex}, we focus our search on articles
% published from that year onward. The search results from each database were
% merged and deduplicated with SLR Tool\citep{slrtool}. Specifically, we obtained
% 373 articles from ACM Digital Library, 213 articles from arXiv, 9 articles
% from IEEE Xplore, and 1187 articles from Springer.
\paragraph{搜索数据库}. 确定搜索字符串后，我们使用SLR工具\citep{slrtool}在四个广泛
使用的数据库
\footnote{ACM Digital Library, arXiv, IEEE Xplore, Springer}上进行了自动化搜索，
这些数据库涵盖了大多数已发表的文章和正在审核的预印本文章。
由于第一个在代码语料库上训练的LLM是在2021年发布的\citep{codex}
，我们将搜索重点放在从那年开始发表的文章上。
每个数据库的搜索结果都通过SLR工具\citep{slrtool}进行了合并和去重。
具体来说，我们从ACM Digital Library获得了373篇文章，从arXiv获得了213篇文章，
从IEEE Xplore获得了9篇文章，从Springer获得了1187篇文章。

% \section{Study Selection}\label{sec:selection}
\section{研究选择}\label{sec:selection}

\begin{table}[ht]
    % \caption{Inclusion and Exclusion Criteria}
    \centering
    \caption{包含和排除标准}
    % Inclusion: The article claims that an LLM is used;
    % The article claims that the study involves an debugging task;
    % The article is full-text accessible.
    % Exclusion:
    % Short articles with less than 8 pages;
    % Tool demos and editorials;
    % Duplicate articles or similar studies with different versions from the same author.
    \label{tab:criteria}
\begin{tabular}{ll}
\hline
\multicolumn{2}{l}{Inclusion Criteria} \\ \hline
(1)                 & 文章声称大语言模型被应用 \\
(2)                 & 文章声称研究解决的是代码调试问题 \\
(3)                 & 文章全文可以访问 \\ \hline
\multicolumn{2}{l}{Exclusion Criteria} \\ \hline
(1)                 & 重复或来自同一作者不同版本的文章 \\
(2)                 & 工具展示,新闻报道或教程  \\
(3)                 & 非英语写作的文章 \\ \hline
\end{tabular}
\end{table}

% \par Using our search strategy, we initially obtained 1782 articles
% that potentially relate to our research. Next, we further 
% evaluate the relevance of these articles based on our inclusion
% and exclusion criteria, as shown in Table~\ref{tab:criteria}.
% In this step, we conducted a manual selection by examining the 
% title, abstract, and keywords of each article, resulting
% in a total of \TODO{} papers.
\par 使用我们的搜索策略，我们最初获得了1782篇可能与我们的研究相关的文章。
接下来，我们根据表\ref{tab:criteria}中所示的包含和排除标准进一步评估这些
文章的相关性。
在这一步中，我们通过检查每篇文章的标题、摘要和关键词进行手动选择，
最终得到了TODO篇论文。

% \paragraph{Snowballing Search. } To identify any additional 
% possibly relevant primary studies, we conducted a snowballing 
% search. Snowballing search refers to using the reference list
% of an article or the citations to the article to identify additional
% articles. As a result, we obtained an additional TODO papers.
\paragraph{滚雪球式搜索\citep{llm4se2}} 为了识别任何可能相关的主要研究，
我们进行了滚雪球式搜索。
滚雪球式搜索是指使用文章的参考文献列表或对该文章的引用来识别其他文章。结果，
我们获得了额外的TODO篇论文。

% \section{Data Extraction and Analysis}\label{sec:analysis}
\section{数据提取与分析}\label{sec:analysis}

% \par To provide a comprehensive overview of the LLM for automatic debugging
% task, it is important to fully comprehend how these models are currently
% being applied to bug localization, reproduction, and repairment; as well
% as the challenges they are facing.
% In this section, we try to answer the following research questions:

\par 为了全面概述LLM在自动调试任务中的应用，重要的是要充分理解这些模型目前是如何被应用于
错误定位、重现和修复的，以及它们面临的挑战。
在本节中，我们尝试回答以下研究问题：

% \paragraph{RQ1}: How are debugging-related datasets collected, preprocessed,
% and used in LLMs? \textit{RQ1} aims to discover the strategies of
% dataset collection, the criteria for dataset selection and the 
% pre-processing steps necessary for boosting the performances of coding 
% LLMs. We also provide a list of up-to-date benchmarks,
% which are based on real-world scenarios, for evaluating
% LLM-based program repair techniques.
\paragraph{RQ1:} 调试相关的数据集是如何被收集、预处理和应用于LLMs的？
\textit{RQ1}旨在发现数据集收集的策略、
数据集选择的标准以及提升编码LLMs性能所需的预处理步骤。我们还提供了
一个基于真实场景的最新基准列表，用于评估基于LLM的程序修复技术。

% \paragraph{RQ2}: what techniques are applied to improve the performance
% of large language models\footnote{and agentic systems} for program 
% repairment? \textit{RQ2} explores the effectiveness 
% of different optimization techniques in the context of LLM for 
% automatic program repairment. This includes an investigation into 
% Retrieval Augmentation \citep{ragnlp, ragsurvey}, 
% Prompt Engineering \citep{promptsurvey}, as well as Agentic 
% Corportation \citep{agents}, which are designed to enhance the performance of
% LLMs on various NLP tasks.

\paragraph{RQ2:} 目前有哪些技术被应用于提升大语言模型\footnote{以及多智能体系统}
在程序修复方面的性能？\textit{RQ2}探讨了不同优化技术在LLM自动程序修复背景下
的有效性。这包括对检索增强\citep{ragnlp, ragsurvey}
、提示词工程\citep{promptsurvey}、和多智能体协作\citep{agents}等
用于增强大语言模型表现技术的总结。

% \paragraph{RQ3: } how do researchers verify the correctness of patches
% generated by code LLMs? Fixing bugs may introduce new bugs in a subtle
% way and potentially affect the end-use, 
% especially when the bugs are fixed by developers who does not have 
% enough knowledge of the repository \citep{incorrectfix}.
% Moreover, the code generated LLM may contain bugs or vulnerabilities.
% For instance, Pearce et al. prompt Github Copilot\citep{copilot} to 
% generate code in scenarios relevant to high-risk cybersecurity 
% weaknesses, and found that 40\% of 1689 programs are vulnerable
% \citep{copilotsecurity}.
% This RQ hence aims to uncover common patch verification techniques, 
% including formal verification and enhanced unit testing, and their 
% effectiveness.

\paragraph{RQ3:} 研究人员如何验证代码LLMs生成的补丁的正确性\citep{patchcorrectness}？
修复错误可能以微妙的方式引入新的错误，并可能影响最终用户，尤
其是当错误由对代码库没有足够了解的开发人员修复时\citep{incorrectfix}。
另外, 大语言模型生成的代码可能有缺陷和安全漏洞; 例如, Pearce et al.
提示Copilot\citep{copilot}在网络安全非常敏感的场景下生成代码, 发现
1689个生成的程序中有40\%有安全漏洞\citep{copilotsecurity}。 
因此，这个研究问题旨在揭示常见的补丁验证技术，包括形式化
验证和增强单元测试，以及它们的有效性。

% \subsection{RQ1: Dataset \& Benchmark}
\subsection{RQ1: 数据集与基准测试}

% \subsection{RQ2: LLM Enhancement Techniques for APR}
\subsection{RQ2: }

% \subsection{RQ3: Patch Verification}
\subsection{RQ3: }
